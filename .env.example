# =============================================================================
# Environment Configuration Template
# =============================================================================
# Copy this file to .env and fill in your values
# Never commit the .env file to version control!

# =============================================================================
# Application Settings
# =============================================================================
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=INFO

# =============================================================================
# API Configuration
# =============================================================================
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4
API_RELOAD=true

# =============================================================================
# UI Configuration
# =============================================================================
UI_HOST=127.0.0.1
UI_PORT=7861

# =============================================================================
# Security
# =============================================================================
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
SECRET_KEY=your-secret-key-here-change-in-production
ENABLE_AUTH=false
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# CORS Origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:7861

# =============================================================================
# Embedding Configuration
# =============================================================================
EMBEDDING_MODEL=paraphrase-multilingual-MiniLM-L12-v2
EMBEDDING_DIMENSION=384
EMBEDDING_DEVICE=cpu
EMBEDDING_BATCH_SIZE=500

# =============================================================================
# Vector Store Configuration
# =============================================================================
VECTOR_STORE_TYPE=chromadb
CHROMA_PERSIST_DIRECTORY=./data/vector_db
CHROMA_COLLECTION_NAME=reddit_conversations_pro

# =============================================================================
# LLM Configuration (Meta Llama 3.1 via Ollama - FREE & LOCAL)
# =============================================================================
# Provider: ollama (recommended), openai, anthropic
LLM_PROVIDER=ollama

# Meta Llama 3.1 8B - Optimal for 16GB RAM
# Alternatives based on RAM:
#   - llama3.2:1b   (4GB RAM - very light)
#   - llama3.2:3b   (8GB RAM - good balance)
#   - llama3.1:8b   (16GB RAM - recommended)
#   - llama3.1:70b  (64GB+ RAM - best quality)
LLM_MODEL=llama3.1:8b

LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=500
LLM_TIMEOUT=60

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434

# OpenAI Configuration (optional - if using openai provider)
OPENAI_API_KEY=your-openai-api-key-here

# Anthropic Configuration (optional - if using anthropic provider)
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# =============================================================================
# Data Paths
# =============================================================================
DATA_RAW_PATH=./data/raw
DATA_PROCESSED_PATH=./data/processed
DATA_VECTOR_DB_PATH=./data/vector_db

# =============================================================================
# Search Configuration
# =============================================================================
SEARCH_DEFAULT_K=5
SEARCH_MIN_SCORE=0.5
SEARCH_MAX_CONTEXT_LENGTH=2000

# =============================================================================
# Rate Limiting
# =============================================================================
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60

# =============================================================================
# Reranker (Cross-Encoder for improved relevance)
# =============================================================================
RERANKER_ENABLED=true
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2
RERANKER_DEVICE=cpu
RERANKER_TOP_K=3

# =============================================================================
# Caching (In-Memory or Redis)
# =============================================================================
ENABLE_CACHING=true
CACHE_BACKEND=memory
CACHE_TTL=3600
REDIS_URL=redis://localhost:6379/0

# =============================================================================
# Conversation Memory
# =============================================================================
MEMORY_MAX_SESSIONS=1000
MEMORY_SESSION_TIMEOUT=3600
MEMORY_MAX_MESSAGES=100
MEMORY_SUMMARY_THRESHOLD=10
MEMORY_KEEP_RECENT=5

# =============================================================================
# Monitoring
# =============================================================================
METRICS_ENABLED=false
PROMETHEUS_PORT=9090

# =============================================================================
# Logging
# =============================================================================
LOG_FORMAT=json
LOG_FILE=./logs/app.log
LOG_ROTATION=100 MB
LOG_RETENTION=30 days

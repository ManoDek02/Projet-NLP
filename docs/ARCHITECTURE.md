# Architecture Technique - Reddit RAG Chatbot

## Table des matiÃ¨res

1. [Vue d'ensemble](#1-vue-densemble)
2. [Architecture systÃ¨me](#2-architecture-systÃ¨me)
3. [Pipeline RAG](#3-pipeline-rag)
4. [Composants techniques](#4-composants-techniques)
5. [Flux de donnÃ©es](#5-flux-de-donnÃ©es)
6. [Stack technologique](#6-stack-technologique)
7. [Structure du projet](#7-structure-du-projet)
8. [API REST](#8-api-rest)
9. [SÃ©curitÃ© et performance](#9-sÃ©curitÃ©-et-performance)
10. [DÃ©ploiement](#10-dÃ©ploiement)

---

## 1. Vue d'ensemble

### 1.1 Description du projet

Le **Reddit RAG Chatbot** est un systÃ¨me de question-rÃ©ponse intelligent basÃ© sur l'architecture RAG (Retrieval-Augmented Generation). Il utilise une base de connaissances de **56 297 conversations Reddit** pour fournir des rÃ©ponses contextuelles et pertinentes en **franÃ§ais et anglais**.

### 1.2 Objectifs

| Objectif | Description |
|----------|-------------|
| **Pertinence** | Fournir des rÃ©ponses basÃ©es sur des conversations rÃ©elles |
| **Multilingue** | Support franÃ§ais/anglais avec rÃ©ponse dans la langue de la question |
| **Performance** | Temps de rÃ©ponse < 3 secondes |
| **ScalabilitÃ©** | Architecture modulaire et extensible |

### 1.3 CaractÃ©ristiques principales

- Architecture RAG (Retrieval-Augmented Generation)
- Support multilingue (60+ langues)
- API REST documentÃ©e (OpenAPI/Swagger)
- Interface web moderne (HTML/CSS/JS)
- LLM cloud via Groq (gratuit et rapide)
- Base vectorielle persistante (ChromaDB)

---

## 2. Architecture systÃ¨me

### 2.1 Diagramme d'architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              COUCHE PRÃ‰SENTATION                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Frontend Web      â”‚         â”‚         API REST (FastAPI)          â”‚   â”‚
â”‚  â”‚   (HTML/CSS/JS)     â”‚ â”€â”€â”€â”€â”€â”€â–º â”‚    http://localhost:8000/api/v1     â”‚   â”‚
â”‚  â”‚   Port: 3000        â”‚  HTTP   â”‚    - POST /chat/                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚    - GET /chat/stats                â”‚   â”‚
â”‚                                  â”‚    - GET /health/                   â”‚   â”‚
â”‚                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              COUCHE SERVICE                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                      â”‚     ChatbotService          â”‚                        â”‚
â”‚                      â”‚  (Orchestration RAG)        â”‚                        â”‚
â”‚                      â”‚                             â”‚                        â”‚
â”‚                      â”‚  â€¢ Validation des entrÃ©es   â”‚                        â”‚
â”‚                      â”‚  â€¢ Coordination des servicesâ”‚                        â”‚
â”‚                      â”‚  â€¢ Gestion des erreurs      â”‚                        â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                    â”‚                                        â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚              â–¼                     â–¼                     â–¼                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ EmbeddingService  â”‚ â”‚ VectorStoreServiceâ”‚ â”‚    LLMService     â”‚         â”‚
â”‚  â”‚                   â”‚ â”‚                   â”‚ â”‚                   â”‚         â”‚
â”‚  â”‚ â€¢ Vectorisation   â”‚ â”‚ â€¢ Stockage        â”‚ â”‚ â€¢ GÃ©nÃ©ration      â”‚         â”‚
â”‚  â”‚ â€¢ Batch processingâ”‚ â”‚ â€¢ Recherche       â”‚ â”‚ â€¢ Multi-provider  â”‚         â”‚
â”‚  â”‚ â€¢ Multilingue     â”‚ â”‚ â€¢ SimilaritÃ©      â”‚ â”‚ â€¢ Groq/Ollama     â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                     â”‚                     â”‚
                â–¼                     â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              COUCHE DONNÃ‰ES                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  Sentence         â”‚ â”‚    ChromaDB       â”‚ â”‚    Groq API       â”‚         â”‚
â”‚  â”‚  Transformers     â”‚ â”‚                   â”‚ â”‚                   â”‚         â”‚
â”‚  â”‚                   â”‚ â”‚  â€¢ 56,297 docs    â”‚ â”‚  â€¢ Llama 3.1 8B   â”‚         â”‚
â”‚  â”‚  â€¢ MiniLM-L12-v2  â”‚ â”‚  â€¢ SQLite backend â”‚ â”‚  â€¢ Cloud hosted   â”‚         â”‚
â”‚  â”‚  â€¢ 384 dimensions â”‚ â”‚  â€¢ Persistant     â”‚ â”‚  â€¢ Gratuit        â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Architecture en couches

| Couche | ResponsabilitÃ© | Technologies |
|--------|---------------|--------------|
| **PrÃ©sentation** | Interface utilisateur, API HTTP | HTML/CSS/JS, FastAPI |
| **Service** | Logique mÃ©tier, orchestration | Python, Pydantic |
| **DonnÃ©es** | Stockage, embeddings, LLM | ChromaDB, Sentence Transformers, Groq |

---

## 3. Pipeline RAG

### 3.1 Qu'est-ce que RAG ?

**RAG (Retrieval-Augmented Generation)** est une architecture qui combine :
- **Retrieval** : Recherche de documents pertinents dans une base de connaissances
- **Augmented** : Enrichissement du contexte avec les documents trouvÃ©s
- **Generation** : GÃ©nÃ©ration de rÃ©ponse par un LLM avec ce contexte

### 3.2 Pourquoi RAG ?

| Approche | Avantages | InconvÃ©nients |
|----------|-----------|---------------|
| **LLM seul** | Simple | Hallucinations, pas de donnÃ©es spÃ©cifiques |
| **Fine-tuning** | PersonnalisÃ© | CoÃ»teux, donnÃ©es figÃ©es |
| **RAG** | DonnÃ©es Ã  jour, traÃ§able, pas d'hallucination | Plus complexe |

### 3.3 Pipeline dÃ©taillÃ©

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           PIPELINE RAG COMPLET                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHASE 1: INDEXATION (Offline - une seule fois)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  DonnÃ©es     â”‚     â”‚  Nettoyage   â”‚     â”‚  GÃ©nÃ©ration  â”‚
    â”‚  Reddit CSV  â”‚ â”€â”€â–º â”‚  & Validationâ”‚ â”€â”€â–º â”‚  Embeddings  â”‚
    â”‚  (56,297)    â”‚     â”‚              â”‚     â”‚  (384 dim)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                                                     â–¼
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                              â”‚  Stockage    â”‚
                                              â”‚  ChromaDB    â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHASE 2: INFÃ‰RENCE (Online - Ã  chaque requÃªte)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Question   â”‚
    â”‚  Utilisateurâ”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Validation â”‚     â”‚  Embedding  â”‚     â”‚  Recherche  â”‚
    â”‚  & Nettoyageâ”‚ â”€â”€â–º â”‚  Question   â”‚ â”€â”€â–º â”‚  SimilaritÃ© â”‚
    â”‚             â”‚     â”‚  (384 dim)  â”‚     â”‚  Top-K (5)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                                                   â–¼
                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                            â”‚  Documents  â”‚
                                            â”‚  Pertinents â”‚
                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Constructionâ”‚     â”‚  GÃ©nÃ©ration â”‚     â”‚  RÃ©ponse    â”‚
    â”‚  Prompt +   â”‚ â”€â”€â–º â”‚  LLM (Groq) â”‚ â”€â”€â–º â”‚  Finale     â”‚
    â”‚  Contexte   â”‚     â”‚  Llama 3.1  â”‚     â”‚             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.4 Ã‰tapes dÃ©taillÃ©es

#### Ã‰tape 1 : RÃ©ception de la question
```python
# Exemple de requÃªte
{
    "message": "Quel tÃ©lÃ©phone me recommandes-tu ?",
    "use_llm": true,
    "n_results": 5
}
```

#### Ã‰tape 2 : Validation et nettoyage
- VÃ©rification de la longueur (max 1000 caractÃ¨res)
- Suppression des caractÃ¨res spÃ©ciaux
- DÃ©tection d'injections potentielles

#### Ã‰tape 3 : Vectorisation (Embedding)
```python
# Conversion texte â†’ vecteur 384 dimensions
embedding = embedding_service.embed_text("Quel tÃ©lÃ©phone me recommandes-tu ?")
# RÃ©sultat: [0.023, -0.156, 0.089, ..., 0.045]  # 384 valeurs float
```

**Pourquoi les embeddings ?**
- ReprÃ©sentation sÃ©mantique du texte
- Permet la recherche par similaritÃ©
- Multilingue : "phone" â‰ˆ "tÃ©lÃ©phone" dans l'espace vectoriel

#### Ã‰tape 4 : Recherche par similaritÃ©
```python
# Recherche des K conversations les plus similaires
results = vector_store.search(embedding, n_results=5)
# Utilise la similaritÃ© cosinus pour le ranking
```

**SimilaritÃ© cosinus** :
```
similarity(A, B) = (A Â· B) / (||A|| Ã— ||B||)
```
- RÃ©sultat entre 0 et 1
- 1 = identique, 0 = aucun rapport

#### Ã‰tape 5 : Construction du prompt
```python
prompt = f"""
Context from Reddit conversations:
1. User asked about phones, response: "I recommend the iPhone 14..."
2. Discussion about smartphones: "Samsung Galaxy S23 is great..."

User question: Quel tÃ©lÃ©phone me recommandes-tu ?

IMPORTANT: Respond in French (same language as the question).
"""
```

#### Ã‰tape 6 : GÃ©nÃ©ration LLM
```python
response = groq_client.chat.completions.create(
    model="llama-3.1-8b-instant",
    messages=[
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": prompt}
    ]
)
```

#### Ã‰tape 7 : Retour de la rÃ©ponse
```python
{
    "message": "Je te recommande le Samsung Galaxy S23 ou l'iPhone 14...",
    "sources": [...],
    "metadata": {
        "duration_ms": 1523,
        "method": "llm",
        "model": "llama-3.1-8b-instant"
    }
}
```

---

## 4. Composants techniques

### 4.1 EmbeddingService

**RÃ´le** : Convertir le texte en vecteurs numÃ©riques pour la recherche sÃ©mantique.

**Fichier** : `src/core/embeddings.py`

```python
class EmbeddingService:
    """Service d'embeddings multilingues"""

    model: str = "paraphrase-multilingual-MiniLM-L12-v2"
    dimension: int = 384

    def embed_text(self, text: str) -> List[float]:
        """Convertit un texte en vecteur"""

    def embed_batch(self, texts: List[str]) -> List[List[float]]:
        """Traitement par lots pour l'indexation"""
```

**CaractÃ©ristiques** :

| ParamÃ¨tre | Valeur |
|-----------|--------|
| ModÃ¨le | `paraphrase-multilingual-MiniLM-L12-v2` |
| Dimensions | 384 |
| Langues | 60+ |
| Performance | ~10ms par texte |
| Taille modÃ¨le | ~120MB |

### 4.2 VectorStoreService

**RÃ´le** : Stocker et rechercher des vecteurs efficacement.

**Fichier** : `src/core/vector_store.py`

```python
class VectorStoreService:
    """Service de stockage vectoriel avec ChromaDB"""

    def add_conversations(self, conversations: List[Conversation]):
        """Indexe des conversations"""

    def search(self, embedding: List[float], n_results: int) -> List[SearchResult]:
        """Recherche par similaritÃ© cosinus"""

    def count(self) -> int:
        """Nombre de documents indexÃ©s"""
```

**CaractÃ©ristiques** :

| ParamÃ¨tre | Valeur |
|-----------|--------|
| Backend | ChromaDB |
| Stockage | SQLite + fichiers binaires |
| Collection | `reddit_conversations_pro` |
| Documents | 56,297 |
| MÃ©trique | SimilaritÃ© cosinus |

### 4.3 LLMService

**RÃ´le** : GÃ©nÃ©rer des rÃ©ponses naturelles Ã  partir du contexte.

**Fichier** : `src/core/llm_handler.py`

```python
class LLMService:
    """Service LLM multi-provider"""

    providers = ["groq", "ollama", "openai", "anthropic"]

    def generate(self, query: str, context: str) -> str:
        """GÃ©nÃ¨re une rÃ©ponse avec le contexte RAG"""
```

**Providers supportÃ©s** :

| Provider | ModÃ¨le | Vitesse | CoÃ»t |
|----------|--------|---------|------|
| **Groq** âœ… | llama-3.1-8b-instant | ~1-2s | Gratuit |
| Ollama | llama3:8b | ~30-60s | Gratuit (local) |
| OpenAI | gpt-4o-mini | ~2-3s | Payant |
| Anthropic | claude-3-haiku | ~2-3s | Payant |

### 4.4 ChatbotService

**RÃ´le** : Orchestrer le pipeline RAG complet.

**Fichier** : `src/services/chatbot_service.py`

```python
class ChatbotService:
    """Orchestrateur principal du chatbot"""

    def __init__(self):
        self.embedding_service = EmbeddingService()
        self.vector_store = VectorStoreService()
        self.llm_service = LLMService()

    def chat(self, request: ChatRequest) -> ChatResponse:
        """
        Pipeline complet:
        1. Validation
        2. Embedding
        3. Recherche
        4. GÃ©nÃ©ration (optionnelle)
        5. Formatage rÃ©ponse
        """
```

---

## 5. Flux de donnÃ©es

### 5.1 Diagramme de sÃ©quence

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚Frontendâ”‚     â”‚  API   â”‚     â”‚ Chatbot  â”‚     â”‚Embeddingâ”‚     â”‚Vector â”‚     â”‚ LLM  â”‚
â”‚        â”‚     â”‚FastAPI â”‚     â”‚ Service  â”‚     â”‚ Service â”‚     â”‚ Store â”‚     â”‚ Groq â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”¬â”€â”€â”€â”˜     â””â”€â”€â”¬â”€â”€â”€â”˜
    â”‚              â”‚               â”‚                â”‚              â”‚            â”‚
    â”‚ POST /chat/  â”‚               â”‚                â”‚              â”‚            â”‚
    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚               â”‚                â”‚              â”‚            â”‚
    â”‚              â”‚  chat(req)    â”‚                â”‚              â”‚            â”‚
    â”‚              â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                â”‚              â”‚            â”‚
    â”‚              â”‚               â”‚                â”‚              â”‚            â”‚
    â”‚              â”‚               â”‚ embed_text()   â”‚              â”‚            â”‚
    â”‚              â”‚               â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚              â”‚            â”‚
    â”‚              â”‚               â”‚                â”‚              â”‚            â”‚
    â”‚              â”‚               â”‚   embedding    â”‚              â”‚            â”‚
    â”‚              â”‚               â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚              â”‚            â”‚
    â”‚              â”‚               â”‚                â”‚              â”‚            â”‚
    â”‚              â”‚               â”‚        search(embedding)      â”‚            â”‚
    â”‚              â”‚               â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚            â”‚
    â”‚              â”‚               â”‚                â”‚              â”‚            â”‚
    â”‚              â”‚               â”‚           results             â”‚            â”‚
    â”‚              â”‚               â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚            â”‚
    â”‚              â”‚               â”‚                â”‚              â”‚            â”‚
    â”‚              â”‚               â”‚              generate(query, context)      â”‚
    â”‚              â”‚               â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
    â”‚              â”‚               â”‚                â”‚              â”‚            â”‚
    â”‚              â”‚               â”‚                        response            â”‚
    â”‚              â”‚               â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚              â”‚               â”‚                â”‚              â”‚            â”‚
    â”‚              â”‚   response    â”‚                â”‚              â”‚            â”‚
    â”‚              â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                â”‚              â”‚            â”‚
    â”‚              â”‚               â”‚                â”‚              â”‚            â”‚
    â”‚   JSON       â”‚               â”‚                â”‚              â”‚            â”‚
    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚               â”‚                â”‚              â”‚            â”‚
```

### 5.2 Format des donnÃ©es

#### RequÃªte (ChatRequest)
```json
{
    "message": "Quel tÃ©lÃ©phone me recommandes-tu ?",
    "use_llm": true,
    "n_results": 5
}
```

#### RÃ©ponse (ChatResponse)
```json
{
    "message": "Je te recommande le Samsung Galaxy S23...",
    "sources": [
        {
            "context": "Looking for a new phone recommendation",
            "response": "Samsung Galaxy S23 is great for the price",
            "score": 0.89
        }
    ],
    "metadata": {
        "duration_ms": 1523,
        "method": "llm",
        "model": "llama-3.1-8b-instant",
        "n_sources": 5
    }
}
```

---

## 6. Stack technologique

### 6.1 Backend

| Technologie | Version | Usage |
|-------------|---------|-------|
| **Python** | 3.10+ | Langage principal |
| **FastAPI** | 0.109+ | Framework API REST |
| **Pydantic** | 2.5+ | Validation des donnÃ©es |
| **Uvicorn** | 0.27+ | Serveur ASGI |

### 6.2 Machine Learning / NLP

| Technologie | Version | Usage |
|-------------|---------|-------|
| **Sentence Transformers** | 2.3+ | Embeddings multilingues |
| **ChromaDB** | 0.4+ | Base de donnÃ©es vectorielle |
| **Groq SDK** | 0.1+ | Client LLM cloud |
| **PyTorch** | 2.2+ | Backend ML |

### 6.3 Frontend

| Technologie | Usage |
|-------------|-------|
| **HTML5** | Structure sÃ©mantique |
| **CSS3** | Styles (variables CSS, flexbox, grid, animations) |
| **JavaScript ES6+** | Logique, appels API (fetch async/await) |

### 6.4 Outils de dÃ©veloppement

| Outil | Usage |
|-------|-------|
| **Ruff** | Linting et formatage Python |
| **Pytest** | Tests unitaires |
| **Loguru** | Logging structurÃ© |

---

## 7. Structure du projet

```
ğŸ“ Projet-NLP/
â”‚
â”œâ”€â”€ ğŸ“ api/                          # API REST FastAPI
â”‚   â”œâ”€â”€ main.py                      # Point d'entrÃ©e, middleware, routes
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ chat.py                  # POST /chat/, GET /stats, GET /examples
â”‚   â”‚   â””â”€â”€ health.py                # GET /health/, /ready, /live
â”‚   â””â”€â”€ schemas/
â”‚       â”œâ”€â”€ request.py               # ChatRequest, SearchRequest
â”‚       â””â”€â”€ response.py              # ChatResponse, ErrorResponse
â”‚
â”œâ”€â”€ ğŸ“ src/                          # Code source principal
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ settings.py              # Configuration centralisÃ©e (Pydantic)
â”‚   â”‚   â””â”€â”€ logging_config.py        # Configuration Loguru
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                        # Services principaux
â”‚   â”‚   â”œâ”€â”€ embeddings.py            # EmbeddingService (Sentence Transformers)
â”‚   â”‚   â”œâ”€â”€ vector_store.py          # VectorStoreService (ChromaDB)
â”‚   â”‚   â””â”€â”€ llm_handler.py           # LLMService (Groq/Ollama/OpenAI)
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ chatbot_service.py       # ChatbotService (orchestration RAG)
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py               # ModÃ¨les Pydantic (Conversation, etc.)
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ data_loader.py           # Chargement CSV/JSON
â”‚       â”œâ”€â”€ text_processor.py        # Nettoyage, normalisation
â”‚       â””â”€â”€ validators.py            # Validation entrÃ©es, sÃ©curitÃ©
â”‚
â”œâ”€â”€ ğŸ“ frontend/                     # Interface web moderne
â”‚   â”œâ”€â”€ index.html                   # Structure HTML (sidebar, chat, stats)
â”‚   â”œâ”€â”€ styles.css                   # CSS moderne (variables, animations)
â”‚   â””â”€â”€ app.js                       # JavaScript (fetch API, DOM)
â”‚
â”œâ”€â”€ ğŸ“ data/                         # DonnÃ©es
â”‚   â”œâ”€â”€ raw/                         # DonnÃ©es brutes
â”‚   â”‚   â””â”€â”€ casual_data_windows.csv  # 56,297 conversations Reddit
â”‚   â”œâ”€â”€ processed/                   # DonnÃ©es traitÃ©es
â”‚   â”‚   â””â”€â”€ conversations.json       # Format JSON nettoyÃ©
â”‚   â””â”€â”€ vector_db/                   # Base vectorielle
â”‚       â””â”€â”€ chroma_db/               # Fichiers ChromaDB
â”‚
â”œâ”€â”€ ğŸ“ scripts/                      # Scripts utilitaires
â”‚   â”œâ”€â”€ prepare_data.py              # CSV â†’ JSON (nettoyage)
â”‚   â””â”€â”€ index_conversations.py       # JSON â†’ ChromaDB (embeddings)
â”‚
â”œâ”€â”€ ğŸ“ docs/                         # Documentation
â”‚   â””â”€â”€ ARCHITECTURE.md              # Ce document
â”‚
â”œâ”€â”€ .env                             # Variables d'environnement
â”œâ”€â”€ .env.example                     # Template de configuration
â”œâ”€â”€ requirements.txt                 # DÃ©pendances Python
â”œâ”€â”€ run_api.py                       # python run_api.py â†’ :8000
â””â”€â”€ run_frontend.py                  # python run_frontend.py â†’ :3000
```

---

## 8. API REST

### 8.1 Endpoints

#### POST /api/v1/chat/
Envoyer un message et recevoir une rÃ©ponse.

```bash
curl -X POST "http://localhost:8000/api/v1/chat/" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Quel tÃ©lÃ©phone acheter ?",
    "use_llm": true,
    "n_results": 5
  }'
```

**ParamÃ¨tres** :

| ParamÃ¨tre | Type | DÃ©faut | Description |
|-----------|------|--------|-------------|
| `message` | string | requis | Question de l'utilisateur |
| `use_llm` | boolean | false | Utiliser le LLM pour gÃ©nÃ©rer |
| `n_results` | integer | 5 | Nombre de sources RAG |

#### GET /api/v1/chat/stats
Obtenir les statistiques du chatbot.

```json
{
    "total_conversations": 56297,
    "embedding_model": "paraphrase-multilingual-MiniLM-L12-v2",
    "llm_provider": "groq",
    "llm_model": "llama-3.1-8b-instant",
    "llm_available": true
}
```

#### GET /api/v1/chat/examples
Obtenir des exemples de questions.

```json
{
    "french": ["Quel tÃ©lÃ©phone acheter ?", ...],
    "english": ["What phone should I buy?", ...]
}
```

#### GET /api/v1/health/
VÃ©rifier l'Ã©tat de santÃ© du service.

```json
{
    "status": "healthy",
    "version": "2.0.0",
    "services": {
        "embedding": "ok",
        "vector_store": "ok",
        "llm": "ok"
    }
}
```

### 8.2 Documentation interactive

| URL | Description |
|-----|-------------|
| http://localhost:8000/docs | Swagger UI (interactif) |
| http://localhost:8000/redoc | ReDoc (documentation) |
| http://localhost:8000/openapi.json | SchÃ©ma OpenAPI |

---

## 9. SÃ©curitÃ© et performance

### 9.1 SÃ©curitÃ©

| Mesure | ImplÃ©mentation |
|--------|----------------|
| **Validation des entrÃ©es** | Max 1000 caractÃ¨res, sanitization |
| **DÃ©tection d'injection** | Patterns SQL/XSS bloquÃ©s |
| **CORS** | Origines configurables |
| **Rate limiting** | 100 requÃªtes/minute |
| **Logging** | TraÃ§abilitÃ© complÃ¨te |

### 9.2 Performance

| MÃ©trique | Valeur |
|----------|--------|
| Temps de recherche vectorielle | < 100ms |
| Temps d'embedding | ~10ms |
| Temps LLM (Groq) | ~1-3s |
| **Temps total** | **~2-4s** |
| MÃ©moire API | ~500MB |
| MÃ©moire embeddings | ~200MB |
| Taille base vectorielle | ~500MB |

### 9.3 Optimisations appliquÃ©es

1. **Singleton pattern** : Services instanciÃ©s une seule fois
2. **Lazy loading** : ModÃ¨les chargÃ©s Ã  la demande
3. **Batch processing** : Indexation par lots de 500
4. **Connection pooling** : RÃ©utilisation des connexions

---

## 10. DÃ©ploiement

### 10.1 PrÃ©requis

- Python 3.10+
- 4GB RAM minimum (8GB recommandÃ©)
- ClÃ© API Groq (gratuite sur console.groq.com)

### 10.2 Installation

```bash
# 1. Cloner le projet
git clone <repository>
cd Projet-NLP

# 2. CrÃ©er environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. Configurer les variables d'environnement
cp .env.example .env
# Ã‰diter .env avec votre clÃ© GROQ_API_KEY

# 5. Indexer les donnÃ©es (si pas dÃ©jÃ  fait)
python scripts/prepare_data.py
python scripts/index_conversations.py
```

### 10.3 Lancement

```bash
# Terminal 1 - API (obligatoire)
python run_api.py
# â†’ http://localhost:8000

# Terminal 2 - Frontend
python run_frontend.py
# â†’ http://localhost:3000
```

### 10.4 Variables d'environnement

```bash
# .env
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=INFO

# API
API_HOST=127.0.0.1
API_PORT=8000

# LLM (Groq - gratuit et rapide)
LLM_PROVIDER=groq
LLM_MODEL=llama-3.1-8b-instant
GROQ_API_KEY=gsk_xxxxxxxxxxxxx

# Embeddings
EMBEDDING_MODEL=paraphrase-multilingual-MiniLM-L12-v2
EMBEDDING_DEVICE=cpu
```

---

## Annexes

### A. Glossaire

| Terme | DÃ©finition |
|-------|------------|
| **RAG** | Retrieval-Augmented Generation - Architecture combinant recherche et gÃ©nÃ©ration |
| **Embedding** | ReprÃ©sentation vectorielle d'un texte |
| **LLM** | Large Language Model - ModÃ¨le de langage (ex: Llama, GPT) |
| **SimilaritÃ© cosinus** | Mesure de similaritÃ© entre vecteurs |
| **ChromaDB** | Base de donnÃ©es vectorielle open-source |
| **Groq** | Plateforme cloud pour LLM (gratuit) |

### B. MÃ©triques du projet

| MÃ©trique | Valeur |
|----------|--------|
| Conversations indexÃ©es | 56,297 |
| Dimension des embeddings | 384 |
| Langues supportÃ©es | 60+ |
| Temps de rÃ©ponse moyen | ~2-3s |
| Taille totale du projet | ~600MB |

### C. RÃ©fÃ©rences

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [ChromaDB Documentation](https://docs.trychroma.com/)
- [Sentence Transformers](https://www.sbert.net/)
- [Groq API](https://console.groq.com/)
- [RAG Paper (Lewis et al., 2020)](https://arxiv.org/abs/2005.11401)

---

**Document rÃ©digÃ© pour le projet NLP - Reddit RAG Chatbot**
**Version** : 2.0.0
**DerniÃ¨re mise Ã  jour** : FÃ©vrier 2025
